{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#exercicio-i-machine-learning","title":"Exerc\u00edcio I - Machine Learning","text":""},{"location":"#exploracao-kaggle-dataset-tesla-stock-data","title":"Explora\u00e7\u00e3o Kaggle Dataset - TESLA Stock Data","text":"Edi\u00e7\u00e3o <p>2025.2</p>"},{"location":"#grupo","title":"Grupo","text":"<ol> <li>M\u00e1rcio Alexandroni da Silva Filho</li> </ol> <p>\ud83d\udcc2 Sobre o Dataset</p> <p>Fonte: Kaggle (dados hist\u00f3ricos de a\u00e7\u00f5es da Tesla).</p> <p>Per\u00edodo: 6/29/2010 a 3/24/2022</p> <p>Colunas t\u00edpicas:     Date \u2192 Data de negocia\u00e7\u00e3o     Open \u2192 Pre\u00e7o de abertura     High \u2192 Maior pre\u00e7o no dia     Low \u2192 Menor pre\u00e7o no dia     Close \u2192 Pre\u00e7o de fechamento     Adj Close \u2192 Pre\u00e7o ajustado (leva em conta splits e dividendos)     Volume \u2192 Quantidade de a\u00e7\u00f5es negociadas</p>"},{"location":"#entregas","title":"Entregas","text":"<ul> <li> Escolha do Dataset</li> <li> Limpeza dos Dados</li> <li> Normaliza\u00e7\u00e3o e Padroniza\u00e7\u00e3o</li> <li> Diagramas Mermaid do Projeto</li> <li> Visualiza\u00e7\u00f5es</li> <li> \u00c1rvore de Decis\u00e3o</li> <li> Exerc\u00edcio Conclu\u00eddo</li> </ul>"},{"location":"#diagramas","title":"Diagramas","text":"<p>Feito diagramas Mermaid para a cria\u00e7\u00e3o dos diagramas de documenta\u00e7\u00e3o.</p>"},{"location":"#pipeline-do-projeto","title":"Pipeline do projeto","text":"<p>O pipeline mostra o fluxo de etapas do trabalho, desde o dataset bruto at\u00e9 a avalia\u00e7\u00e3o do modelo. Inclui: limpeza dos dados, cria\u00e7\u00e3o de novas vari\u00e1veis (Change e escalas), defini\u00e7\u00e3o do target (Subiu/Caiu), divis\u00e3o treino/teste, treinamento da \u00e1rvore de decis\u00e3o e avalia\u00e7\u00e3o do desempenho.</p> <pre><code>flowchart TD\n    A[Dataset TSLA] --&gt; B[Data Cleaning]\n    B --&gt; C[Feature Engineering - Change, scales]\n    C --&gt; D[Normalization and Standardization]\n    D --&gt; E[Target Definition - Up/Down]\n    E --&gt; F[Train/Test Split]\n    F --&gt; G[Decision Tree]\n    G --&gt; H[Evaluation - metrics]\n\n    %% classes\n    class A,B,C,D,E,F,H orange\n    class G red\n\n    %% class defs (same as your working sample)\n    classDef red fill:#f55\n    classDef orange fill:#ffa500</code></pre>"},{"location":"#logica-do-target","title":"L\u00f3gica do Target","text":"<p>A l\u00f3gica do target define como criamos a vari\u00e1vel de sa\u00edda do modelo: se a varia\u00e7\u00e3o di\u00e1ria de fechamento (Change) for positiva, marcamos como 1 (Subiu); se for negativa ou zero, marcamos como 0 (Caiu).</p> <pre><code>flowchart TD\n    S(Compute Change) --&gt; Q(Change &gt; 0?)\n    Q --&gt;|Yes| U(Target = 1 Up)\n    Q --&gt;|No| D(Target = 0 Down)\n\n    %% classes\n    class S,Q,D,U orange\n    class U red\n\n    %% class defs\n    classDef red fill:#f55\n    classDef orange fill:#ffa500</code></pre>"},{"location":"#exemplo-de-video","title":"Exemplo de v\u00eddeo","text":"<ul> <li>Em Breve</li> </ul>"},{"location":"#referencias","title":"Refer\u00eancias","text":"<p>Material for MkDocs</p>"},{"location":"Data%20Cleaning%20Normalization%20%26%20Standardization/main/","title":"Main","text":""},{"location":"Data%20Cleaning%20Normalization%20%26%20Standardization/main/#data-cleaning","title":"Data Cleaning","text":"<p>A limpeza de dados no dataset da Tesla envolveu a convers\u00e3o da coluna de datas para o formato datetime, a ordena\u00e7\u00e3o cronol\u00f3gica das observa\u00e7\u00f5es, a remo\u00e7\u00e3o da coluna redundante Adj Close e a verifica\u00e7\u00e3o de duplicatas ou valores ausentes, que n\u00e3o foram encontrados. Essas etapas garantem consist\u00eancia e prepara\u00e7\u00e3o adequada dos dados para a an\u00e1lise e modelagem.</p>"},{"location":"Data%20Cleaning%20Normalization%20%26%20Standardization/main/#data-cleaning","title":"Normaliza\u00e7\u00e3o e Padroniza\u00e7\u00e3o","text":"<p>O dataset foi preparado com as seguintes etapas:</p> <ul> <li> <p>Cria\u00e7\u00e3o da coluna Change (varia\u00e7\u00e3o percentual di\u00e1ria do fechamento).</p> </li> <li> <p>Aplica\u00e7\u00e3o de Normaliza\u00e7\u00e3o (Min-Max) e Padroniza\u00e7\u00e3o (Z-Score) para Volume e Change.</p> </li> <li> <p>Gera\u00e7\u00e3o do arquivo final TSLA_ready.csv contendo: Date, Volume, N-Volume, Z-Volume, Change, N-Change, Z-Change.</p> </li> </ul> <p></p> <p>Sample rows from Dataset the TSLA Stock Data</p>"},{"location":"projeto/main/","title":"Projeto","text":"<p>Aqui vai toda a documenta\u00e7\u00e3o do projeto, incluindo o que j\u00e1 foi feito e o que falta fazer.</p>"},{"location":"roteiro1/main/","title":"Sobre o Dataset","text":""},{"location":"roteiro1/main/#objetivo","title":"Objetivo","text":"<p>Explora\u00e7\u00e3o e An\u00e1lise do Kaggle Dataset 'TESLA Stock Data'</p>"},{"location":"roteiro1/main/#montagem-do-roteiro","title":"Montagem do Roteiro","text":""},{"location":"roteiro1/main/#desafio-i","title":"Desafio I","text":""},{"location":"roteiro1/main/#tarefas-tipicas-de-pre-processamento","title":"Tarefas T\u00edpicas de Pr\u00e9-processamento","text":"Tarefa Descri\u00e7\u00e3o Limpeza de Texto Remove caracteres indesejados, stop words e aplica stemming/lematiza\u00e7\u00e3o. Normaliza\u00e7\u00e3o Padroniza formatos de texto, como datas e moedas. Tokeniza\u00e7\u00e3o Divide o texto em palavras ou subpalavras para facilitar a an\u00e1lise. Extra\u00e7\u00e3o de Atributos Converte o texto em caracter\u00edsticas num\u00e9ricas usando t\u00e9cnicas como TF-IDF ou embeddings. Aumento de Dados Gera dados sint\u00e9ticos para aumentar o tamanho e a diversidade do dataset."},{"location":"roteiro1/main/#plano-do-projeto","title":"Plano do Projeto","text":"<p>Este projeto tem como objetivo analisar, categorizar e estruturar um dataset real \u2014 neste caso, os dados hist\u00f3ricos das a\u00e7\u00f5es da Tesla \u2014 aplicando conceitos fundamentais de Ci\u00eancia de Dados. O processo inclui explora\u00e7\u00e3o inicial, limpeza, cria\u00e7\u00e3o de novas vari\u00e1veis e normaliza\u00e7\u00e3o/padroniza\u00e7\u00e3o, al\u00e9m de visualiza\u00e7\u00f5es que permitem identificar padr\u00f5es e compreender melhor o comportamento dos dados.</p> <p>Como parte desse pipeline, utilizamos a \u00c1rvore de Decis\u00e3o para transformar o problema em uma tarefa de classifica\u00e7\u00e3o, prevendo se o pre\u00e7o de fechamento di\u00e1rio da a\u00e7\u00e3o subiria ou cairia. Essa modelagem exemplifica o uso de algoritmos de Machine Learning dentro de um contexto mais amplo, no qual o foco \u00e9 demonstrar todo o ciclo de prepara\u00e7\u00e3o, an\u00e1lise e leitura de dados que sustentam diferentes experimentos e aplica\u00e7\u00f5es em aprendizado de m\u00e1quina.</p> <ul> <li>Arquivo CSV Originl do TSLA Stock Data:</li> </ul> Date Open High Low Close Adj Close Volume 4/6/2018 60.2 61.856 59.1 59.86 59.86 67601500 8/30/2019 45.83 46.488 44.842 45.122 45.122 46603000 3/11/2014 47.3 48.92 46.486 46.882 46.882 44050500 4/24/2015 44.1 44.16 43.602 43.686 43.686 12139000 10/16/2018 53.14 55.476 52.448 55.318 55.318 47632000 5/13/2015 49.522 49.66 48.45 48.636 48.636 27201000 12/16/2020 628.23 632.5 605 622.77 622.77 42095800 4/18/2019 54.246 54.968 53.95 54.652 54.652 29381500 10/24/2017 67.76 68.56 67.232 67.468 67.468 22458500 12/20/2021 910.7 921.69 893.39 899.94 899.94 18826700 <p>Sample rows from Dataset the TSLA Stock Data</p>"},{"location":"roteiro1/main/#discussoes","title":"Discuss\u00f5es","text":"<ul> <li>Em Breve</li> </ul>"},{"location":"roteiro1/main/#conclusao","title":"Conclus\u00e3o","text":"<p>= Em Breve</p>"},{"location":"roteiro2/main/","title":"Data Cleaning Normalization & Standardization","text":""},{"location":"roteiro2/main/#data-cleaning","title":"Data Cleaning","text":"<p>A limpeza de dados no dataset da Tesla envolveu a convers\u00e3o da coluna de datas para o formato datetime, a ordena\u00e7\u00e3o cronol\u00f3gica das observa\u00e7\u00f5es, a remo\u00e7\u00e3o da coluna redundante Adj Close e a verifica\u00e7\u00e3o de duplicatas ou valores ausentes, que n\u00e3o foram encontrados. Essas etapas garantem consist\u00eancia e prepara\u00e7\u00e3o adequada dos dados para a an\u00e1lise e modelagem.</p>"},{"location":"roteiro2/main/#data-cleaning","title":"Normaliza\u00e7\u00e3o e Padroniza\u00e7\u00e3o","text":"<p>O dataset foi preparado com as seguintes etapas:</p> <ul> <li> <p>Cria\u00e7\u00e3o da coluna Change (varia\u00e7\u00e3o percentual di\u00e1ria do fechamento).</p> </li> <li> <p>Aplica\u00e7\u00e3o de Normaliza\u00e7\u00e3o (Min-Max) e Padroniza\u00e7\u00e3o (Z-Score) para Volume e Change.</p> </li> <li> <p>Gera\u00e7\u00e3o do arquivo final TSLA_ready.csv contendo: Date, Volume, N-Volume, Z-Volume, Change, N-Change, Z-Change.</p> </li> </ul> Date Volume N-Volume Z-Volume Change N-Change Z-Change 2017-06-07 46990000 0.152572 0.561394 0.0192716 0.505743 0.472775 2021-06-29 17381300 0.0552079 -0.497566 -0.0115576 0.437923 -0.393365 2011-03-09 4624000 0.0132571 -0.953833 0.00243309 0.468701 -0.000299921 2021-10-18 24207200 0.077654 -0.253436 0.0321222 0.534012 0.833806 2022-03-24 22901900 0.0733617 -0.300121 0.0148232 0.495957 0.347796 2011-07-06 4634500 0.0132916 -0.953457 -0.00617708 0.44976 -0.2422 2017-03-20 18071500 0.0574775 -0.472881 0.00160612 0.466881 -0.0235335 2012-03-14 4257500 0.0120519 -0.966941 -0.0221668 0.414585 -0.691427 2020-02-25 86452500 0.28234 1.97278 -0.0406337 0.373961 -1.21025 2017-12-19 34125000 0.110267 0.101275 -0.0229292 0.412908 -0.712845 <p>Sample rows from Dataset the TSLA_ready Dataset</p>"},{"location":"roteiro3/main/","title":"Visualiza\u00e7\u00f5es \u00c1rvore","text":""},{"location":"roteiro3/main/#visualizacoes-do-projeto","title":"Visualiza\u00e7\u00f5es do Projeto","text":"<p>Nesta se\u00e7\u00e3o apresentamos as principais visualiza\u00e7\u00f5es geradas a partir do dataset TSLA_ready.csv.</p>"},{"location":"roteiro3/main/#serie-temporal-de-change-com-media-movel-7-dias","title":"S\u00e9rie temporal de Change com M\u00e9dia M\u00f3vel (7 dias)","text":"<p>Aqui adicionamos a m\u00e9dia m\u00f3vel de 7 dias, que suaviza as oscila\u00e7\u00f5es de curto prazo e evidencia tend\u00eancias mais claras.</p> <p></p>"},{"location":"roteiro3/main/#matriz-de-correlacao","title":"Matriz de Correla\u00e7\u00e3o","text":"<p>A matriz de correla\u00e7\u00e3o mostra as rela\u00e7\u00f5es entre Volume, Change e suas vers\u00f5es normalizadas/padronizadas. Ela ajuda a avaliar redund\u00e2ncias e intera\u00e7\u00f5es entre vari\u00e1veis antes da modelagem.</p> <p></p>"},{"location":"roteiro3/main/#matriz-de-confusao","title":"Matriz de Confus\u00e3o","text":"<p>A matriz de confus\u00e3o avalia o desempenho do classificador de \u00c1rvore de Decis\u00e3o em prever se a a\u00e7\u00e3o subiu (1) ou caiu (0). Ela evidencia acertos e erros de classifica\u00e7\u00e3o em cada classe.</p> <p></p>"},{"location":"roteiro4/main/","title":"\u00c1rvore de Decis\u00e3o","text":""},{"location":"roteiro4/main/#arvore-de-decisao-tsla-direcao-do-proximo-dia","title":"\u00c1rvore de Decis\u00e3o \u2014 TSLA (Dire\u00e7\u00e3o do Pr\u00f3ximo Dia)","text":"<p>Configura\u00e7\u00e3o - Alvo: <code>Target(t+1) = 1</code> se <code>Change(t+1) &gt; 0</code> (alta), sen\u00e3o <code>0</code> (queda). - Split temporal: 80% treino / 20% teste. - Hiperpar\u00e2metros: <code>gini</code>, <code>max_depth=5</code>, <code>min_samples_split=20</code>, <code>min_samples_leaf=10</code>, <code>class_weight=balanced</code>. - Features: <code>Volume</code>, <code>N-Volume</code>, <code>Z-Volume</code>, <code>Change</code>, <code>N-Change</code>, <code>Z-Change</code>.</p>"},{"location":"roteiro4/main/#coeficiente-de-gini-impureza","title":"Coeficiente de Gini (impureza)","text":"<p>O Gini mede o qu\u00e3o \u201cmisturado\u201d um n\u00f3 est\u00e1 em termos de classes. - F\u00f3rmula (intui\u00e7\u00e3o): \\( \\text{Gini} = 1 - \\sum p_k^2 \\), onde \\(p_k\\) \u00e9 a propor\u00e7\u00e3o da classe k no n\u00f3. - Quanto menor o Gini, mais \u201cpuro\u201d o n\u00f3 (maioria clara de uma classe). - O algoritmo escolhe os splits que reduzem o Gini (ganho de impureza), deixando os n\u00f3s-filhos mais homog\u00eaneos.</p>"},{"location":"roteiro4/main/#matriz-de-confusao-visao-rapida","title":"Matriz de Confus\u00e3o (vis\u00e3o r\u00e1pida)","text":"<p>A matriz de confus\u00e3o informa o que acertamos e erramos no conjunto de teste:</p> <ul> <li>Verdadeiro Positivo (TP): modelo previu Alta (1) e o pr\u00f3ximo dia realmente foi Alta.  </li> <li>Verdadeiro Negativo (TN): modelo previu Queda (0) e o pr\u00f3ximo dia realmente foi Queda.  </li> <li>Falso Positivo (FP): previu Alta, mas ocorreu Queda.  </li> <li>Falso Negativo (FN): previu Queda, mas ocorreu Alta.</li> </ul> <p>M\u00e9tricas \u00fateis derivadas: - Accuracy: propor\u00e7\u00e3o total de acertos. - Precision (classe 1): entre as Altas previstas, quantas foram Altas de fato? - Recall (classe 1): entre as Altas reais, quantas o modelo acertou? - F1 (classe 1): m\u00e9dia harm\u00f4nica de Precision e Recall (robusta a desequil\u00edbrios).</p> <p>(As tabelas <code>tsla_metrics.csv</code> e <code>tsla_confusion_matrix.csv</code> ficam em <code>docs/roteiro4/</code> para refer\u00eancia t\u00e9cnica.)</p>"},{"location":"roteiro4/main/#conclusao","title":"Conclus\u00e3o","text":"<p>A \u00e1rvore de decis\u00e3o indica que a varia\u00e7\u00e3o do dia corrente (especialmente <code>N-Change</code> e <code>Z-Change</code>) e a intensidade de volume (<code>Volume</code>, <code>N-Volume</code>, <code>Z-Volume</code>) s\u00e3o determinantes para prever a dire\u00e7\u00e3o do dia seguinte. O modelo est\u00e1 regularizado (profundidade e m\u00ednimos por n\u00f3) e respeita a temporalidade (split temporal), o que o torna interpret\u00e1vel e adequado como baseline acad\u00eamico.  </p> <ul> <li>Pontos fortes: regras claras (\u201cse/ent\u00e3o\u201d), import\u00e2ncias de vari\u00e1veis transparentes e facilidade de comunica\u00e7\u00e3o.  </li> <li>Limita\u00e7\u00f5es: por ser um modelo simples, pode n\u00e3o capturar din\u00e2micas de mercado mais complexas. Em trabalhos futuros, vale comparar com ensembles (Random Forest, XGBoost) e valida\u00e7\u00e3o temporal (TimeSeriesSplit).</li> </ul>"},{"location":"roteiro5/main/","title":"KNN","text":""},{"location":"roteiro5/main/#knn-tsla-direcao-do-proximo-dia","title":"KNN \u2014 TSLA (Dire\u00e7\u00e3o do Pr\u00f3ximo Dia)","text":"<p>Objetivo: Classificar a dire\u00e7\u00e3o do pr\u00f3ximo dia (alta=1, queda=0) da TSLA com K-Nearest Neighbors (KNN) usando valida\u00e7\u00e3o temporal.</p>"},{"location":"roteiro5/main/#como-utilizamos-o-knn-no-projeto","title":"Como utilizamos o KNN no projeto","text":"<ul> <li>O que prevemos: <code>Target(t+1)=1</code> se <code>Change(t+1)&gt;0</code>, sen\u00e3o <code>0</code>.</li> <li>Vari\u00e1veis: <code>Volume</code>, <code>N-Volume</code>, <code>Z-Volume</code>, <code>Change</code>, <code>N-Change</code>, <code>Z-Change</code>.</li> <li>Pipeline: Padroniza\u00e7\u00e3o antes de medir dist\u00e2ncias (<code>SimpleImputer(median) \u2192 StandardScaler \u2192 KNN</code>).</li> <li>S\u00e9rie temporal: split <code>80/20</code> + <code>TimeSeriesSplit (5)</code>.</li> <li>Escolha do modelo: maior acur\u00e1cia m\u00e9dia e pico est\u00e1vel na curva de valida\u00e7\u00e3o.</li> <li>erega: pipeline final gera previs\u00e3o e probabilidade; exibimos um badge com o resultado do pen\u00faltimo dia.</li> </ul>"},{"location":"roteiro5/main/#metricas-utilizadas","title":"M\u00e9tricas utilizadas","text":"<ul> <li>Accuracy, Precision/Recall (classe 1), F1 (classe 1) e F1 ponderado.</li> <li>Matriz de confus\u00e3o para leitura de TP/TN/FP/FN e an\u00e1lise de FP vs FN. Arquivos: <code>./knn_tsla_metrics.csv</code>, <code>./knn_tsla_confusion_matrix.csv</code>.</li> </ul>"},{"location":"roteiro5/main/#visualizacoes","title":"Visualiza\u00e7\u00f5es","text":"<p> Dist\u00e2ncias dos k vizinhos ao ponto consultado; cor indica a classe do vizinho.</p> <p> Classe prevista, probabilidade e configura\u00e7\u00e3o do KNN (pen\u00faltimo registro).</p> <p> Acur\u00e1cia m\u00e9dia da valida\u00e7\u00e3o temporal por <code>k</code>.``</p> <p> Heatmap no hold-out (20% final).</p> <p> Fronteira em 2D para uma amostra cont\u00ednua did\u00e1tica da TSLA. M\u00e9trica acima \u00e9 do treino na amostra (ilustrativa).</p> <p> Regi\u00f5es de decis\u00e3o ap\u00f3s PCA(2D) (visualiza\u00e7\u00e3o).</p>"},{"location":"roteiro5/main/#resultado-conclusao","title":"Resultado &amp; conclus\u00e3o","text":"<ul> <li>Sele\u00e7\u00e3o de <code>k</code> guiada pela curva de valida\u00e7\u00e3o com comportamento est\u00e1vel.</li> <li>Avalia\u00e7\u00e3o no teste confirma desempenho conforme m\u00e9tricas e matriz.</li> <li>Com imputa\u00e7\u00e3o, padroniza\u00e7\u00e3o e valida\u00e7\u00e3o temporal, o KNN funciona como baseline n\u00e3o-param\u00e9trico; sinais de varia\u00e7\u00e3o de pre\u00e7o e intensidade de volume aproximam vizinhos da mesma classe.</li> </ul>"},{"location":"roteiro5/main/#limitacoes-proximos-passos","title":"Limita\u00e7\u00f5es &amp; pr\u00f3ximos passos","text":"<ul> <li>Limita\u00e7\u00f5es: custo preditivo (dist\u00e2ncias), sens\u00edvel \u00e0 escala/ru\u00eddo e \u00e0 alta dimensionalidade.</li> <li>Pr\u00f3ximos passos: testar <code>metric='manhattan'</code>, ajustar <code>k</code> por regime de mercado, enriquecer features (m\u00e9dias/volatilidades m\u00f3veis) e comparar com \u00c1rvore/Florestas mantendo <code>TimeSeriesSplit</code>.</li> </ul>"},{"location":"thisdocumentation/main/","title":"This documentation","text":""},{"location":"thisdocumentation/main/#pre-requisitos","title":"Pr\u00e9-requisitos","text":"<p>Antes de come\u00e7ar, certifique-se de que voc\u00ea possui os seguintes pr\u00e9-requisitos instalados em seu sistema:</p> <ul> <li>Git: Para clonar o reposit\u00f3rio.</li> </ul>"},{"location":"thisdocumentation/main/#instalando-o-python","title":"Instalando o Python","text":"LinuxmacOSWindows <p>Instale o Python 3.8 ou superior.</p> <pre><code>sudo apt install python3 python3-venv python3-pip\npython3 --version\n</code></pre> <p>Instale o Python 3.8 ou superior.</p> <pre><code>brew install python\npython3 --version\n</code></pre> <p>Instale o Python 3.13 ou superior. Baixe o instalador do site oficial do Python (https://www.python.org/downloads/) e execute-o. Certifique-se de marcar a op\u00e7\u00e3o \"Add Python to PATH\" durante a instala\u00e7\u00e3o.</p> <pre><code>python --version\n</code></pre>"},{"location":"thisdocumentation/main/#usage","title":"Usage","text":"<p>Para utilizar o c\u00f3digo deste reposit\u00f3rio, siga as instru\u00e7\u00f5es a seguir:</p> <p>Clone ou fork este reposit\u00f3rio:</p> <pre><code>git clone &lt;URL_DO_REPOSITORIO&gt;\n</code></pre> <p>Crie um ambiente virtual do Python:</p> Linux/macOSWindows <pre><code>python3 -m venv env\n</code></pre> <pre><code>python -m venv env\n</code></pre> <p>Ative o ambiente virtual (voc\u00ea deve fazer isso sempre que for executar algum script deste reposit\u00f3rio):</p> Linux/macOSWindows <pre><code>source ./env/bin/activate\n</code></pre> <pre><code>.\\env\\Scripts\\activate\n</code></pre> <p>Instale as depend\u00eancias com:</p> Linux/macOSWindows <pre><code>python3 -m pip install -r requirements.txt --upgrade\n</code></pre> <pre><code>python -m pip install -r requirements.txt --upgrade\n</code></pre>"},{"location":"thisdocumentation/main/#deployment","title":"Deployment","text":"<p>O material utiliza o mkdocs para gerar a documenta\u00e7\u00e3o. Para visualizar a documenta\u00e7\u00e3o, execute o comando:</p> <pre><code>mkdocs serve -o\n</code></pre> <p>Para subir ao GitHub Pages, execute o comando:</p> <pre><code>mkdocs gh-deploy\n</code></pre> <p>Esse reposit\u00f3rio possui um workflow do GitHub Actions que executa o comando <code>mkdocs gh-deploy</code> sempre que houver um push na branch <code>main</code>. Assim, n\u00e3o \u00e9 necess\u00e1rio executar esse comando manualmente. Toda vez que voc\u00ea fizer um push na branch <code>main</code>, a documenta\u00e7\u00e3o ser\u00e1 atualizada automaticamente no GitHub Pages.</p> <p>Aviso 1</p> <p>Para que o github actions funcione corretamente, \u00e9 necess\u00e1rio que o reposit\u00f3rio esteja configurado para que o bot <code>github-actions[bot]</code> tenha permiss\u00e3o de escrita. Voc\u00ea pode verificar isso nas configura\u00e7\u00f5es do reposit\u00f3rio, na se\u00e7\u00e3o \"Actions\" e depois em \"General\". Certifique-se de que a op\u00e7\u00e3o \"Workflow permissions\" esteja definida como \"Read and write permissions\".</p> <p></p> <p>Aviso 2</p> <p>Depois de publicar, caso n\u00e3o consiga acessar a p\u00e1gina, verifique se o github pages est\u00e1 configurado corretamente. V\u00e1 at\u00e9 as configura\u00e7\u00f5es do reposit\u00f3rio, na se\u00e7\u00e3o \"Pages\" e verifique se a branch <code>gh-pages</code> est\u00e1 selecionada como fonte. Se n\u00e3o estiver, selecione-a e salve as altera\u00e7\u00f5es.</p> <p></p> <p>Pay Attention</p> <p>No arquivo '<code>mkdocs.yml</code>, a se\u00e7\u00e3o <code>site_url</code> deve estar configurada corretamente para o seu reposit\u00f3rio. Por exemplo, se o seu reposit\u00f3rio estiver em <code>https://github.com/usuario/repositorio</code>, a se\u00e7\u00e3o <code>site_url</code> deve ser:</p> <pre><code>site_url: https://usuario.github.io/repositorio\n</code></pre> <p>Tamb\u00e9m, certifique-se de que a se\u00e7\u00e3o <code>repo_url</code> esteja configurada corretamente para o seu reposit\u00f3rio. Por exemplo:</p> <pre><code>repo_url: https://github.com/usuario/repositorio\n</code></pre>"}]}